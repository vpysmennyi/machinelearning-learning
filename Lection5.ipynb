{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lection5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUUGlmu5CVvtfkvmPI8ltk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpysmennyi/machinelearning-learning/blob/main/Lection5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7lg_64wMqp-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOYY6vs_PxbJ"
      },
      "source": [
        "train_ds = torchvision.datasets.MNIST('.', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "val_ds = torchvision.datasets.MNIST('.', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvtb_3JigHSC"
      },
      "source": [
        "batch_size = 128\n",
        "hidden_size = 128\n",
        "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle=True)\n",
        "val_dl = DataLoader(train_ds, batch_size = batch_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIClMXDrgUuu",
        "outputId": "642f34d4-805d-42db-a628-8c16df21f142"
      },
      "source": [
        "w1 = nn.Parameter(torch.Tensor(784,hidden_size))\n",
        "b1 = nn.Parameter(torch.Tensor(hidden_size)) #bias\n",
        "\n",
        "w2 = nn.Parameter(torch.Tensor(hidden_size,hidden_size))\n",
        "b2 = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "w3 = nn.Parameter(torch.Tensor(hidden_size,10))\n",
        "b3 = nn.Parameter(torch.Tensor(10))\n",
        "\n",
        "# adjusted normal initialization\n",
        "#nn.init.normal_(w1, std=np.sqrt(1. / 784))\n",
        "#nn.init.normal_(w2, std=np.sqrt(1. / hidden_size))\n",
        "#nn.init.normal_(w3, std=np.sqrt(1. / hidden_size))\n",
        "\n",
        "#Xavier uniform initialization\n",
        "#p = np.sqrt(6)/ np.sqrt(784 + hidden_size)\n",
        "#nn.init.uniform_(w1, -p, p)\n",
        "\n",
        "#p = np.sqrt(6)/ np.sqrt(hidden_size + hidden_size)\n",
        "#nn.init.uniform_(w2, -p, p)\n",
        "\n",
        "#p = np.sqrt(6)/ np.sqrt(hidden_size + 10)\n",
        "#nn.init.uniform_(w3, -p, p)\n",
        "\n",
        "#Kaiming normal initialization\n",
        "nn.init.normal_(w1, std=np.sqrt(2. / 784))\n",
        "nn.init.normal_(w2, std=np.sqrt(2. / hidden_size))\n",
        "nn.init.normal_(w3, std=np.sqrt(2. / hidden_size))\n",
        "\n",
        "nn.init.zeros_(b1)\n",
        "nn.init.zeros_(b2)\n",
        "nn.init.zeros_(b3)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "opt = SGD([w1,b1,w2,b2,w3,b3], lr = 0.1)\n",
        "\n",
        "print(w1.mean(), w1.std())\n",
        "n_epoch = 10\n",
        "\n",
        "for epoch_ind in range(n_epoch):\n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  for batch in train_dl:\n",
        "    opt.zero_grad() #zerofy all gradients, new graph created\n",
        "    X,Y = batch\n",
        "    X = X.reshape((X.shape[0], -1))\n",
        "    #print(X.shape)\n",
        "\n",
        "    y1 = torch.relu(X @ w1 + b1) \n",
        "    y2 = torch.relu(y1 @ w2 + b2)\n",
        "    Yp = torch.softmax(y2 @ w3 + b3, dim=1) #softmax used for multiclass regression, not using sigmoid\n",
        "    \n",
        "    loss = loss_fn(Yp,Y)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step() # w1 = w1 - Dw1 : update weights\n",
        "\n",
        "    epoch_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    accuracy = (Yp.argmax(1) == Y).sum()/len(Y)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "    #print(batch[0].shape, batch[1].shape)\n",
        "    #print(loss)\n",
        "\n",
        "  print(f\"Epoch  {epoch_ind}: Loss: {np.mean(epoch_loss):.6f}\\t Acc={np.mean(epoch_accuracy):.4f}\")\n",
        "\n",
        "  for batch in val_dl:\n",
        "    X,Y = batch\n",
        "    X = X.reshape((X.shape[0], -1))\n",
        "    \n",
        "    y1 = torch.relu(X @ w1 + b1) \n",
        "    y2 = torch.relu(y1 @ w2 + b2)\n",
        "    Yp = torch.softmax(y2 @ w3 + b3, dim=1)\n",
        "\n",
        "    loss = loss_fn(Yp,Y)\n",
        "    epoch_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    accuracy = (Yp.argmax(1) == Y).sum()/len(Y)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "\n",
        "  print(f\"Val Epoch  {epoch_ind}: Loss: {np.mean(epoch_loss):.6f}\\t Acc={np.mean(epoch_accuracy):.4f}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.0002, grad_fn=<MeanBackward0>) tensor(0.0505, grad_fn=<StdBackward0>)\n",
            "Epoch  0: Loss: -0.544045\t Acc=0.5936\n",
            "Val Epoch  0: Loss: -0.628294\t Acc=0.6649\n",
            "Epoch  1: Loss: -0.789051\t Acc=0.8158\n",
            "Val Epoch  1: Loss: -0.799928\t Acc=0.8220\n",
            "Epoch  2: Loss: -0.819479\t Acc=0.8336\n",
            "Val Epoch  2: Loss: -0.822894\t Acc=0.8365\n",
            "Epoch  3: Loss: -0.830314\t Acc=0.8414\n",
            "Val Epoch  3: Loss: -0.832722\t Acc=0.8431\n",
            "Epoch  4: Loss: -0.837173\t Acc=0.8463\n",
            "Val Epoch  4: Loss: -0.838803\t Acc=0.8476\n",
            "Epoch  5: Loss: -0.842327\t Acc=0.8500\n",
            "Val Epoch  5: Loss: -0.843551\t Acc=0.8514\n",
            "Epoch  6: Loss: -0.846765\t Acc=0.8541\n",
            "Val Epoch  6: Loss: -0.847011\t Acc=0.8545\n",
            "Epoch  7: Loss: -0.850076\t Acc=0.8571\n",
            "Val Epoch  7: Loss: -0.851722\t Acc=0.8587\n",
            "Epoch  8: Loss: -0.853433\t Acc=0.8601\n",
            "Val Epoch  8: Loss: -0.854416\t Acc=0.8609\n",
            "Epoch  9: Loss: -0.856147\t Acc=0.8623\n",
            "Val Epoch  9: Loss: -0.857182\t Acc=0.8633\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}