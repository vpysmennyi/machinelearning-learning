{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hometask5_CIFAR100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBpjFq/7FXVjbzCugoXOsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpysmennyi/machinelearning-learning/blob/main/hometask5_CIFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4_9DOcb46ry"
      },
      "source": [
        "CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhuvAd0BqJC5",
        "outputId": "f9ba7f0b-0362-4515-c972-5a17072bc33a"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms \n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "train_ds = CIFAR100('.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "val_ds = CIFAR100('.', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "batch_size = 256\n",
        "hidden_size = 256\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class BatchNorm(nn.Module):\n",
        "  def __init__(self, n_features, momentum=0.1, eps=1e-5):\n",
        "    super(BatchNorm, self).__init__()\n",
        "    self.momentum = momentum\n",
        "    self.eps = eps\n",
        "    \n",
        "    # afine parameters\n",
        "    self.weight = nn.Parameter(torch.Tensor(n_features))\n",
        "    self.bias = nn.Parameter(torch.Tensor(n_features))\n",
        "\n",
        "    # running statistics\n",
        "    self.register_buffer('running_mean', torch.zeros(n_features))\n",
        "    self.register_buffer('running_var', torch.zeros(n_features))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.ones_(self.weight)\n",
        "    nn.init.zeros_(self.bias)\n",
        "    self.running_mean.zero_()\n",
        "    self.running_var.fill_(1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.training:\n",
        "      batch_mean = torch.mean(x, dim=0)\n",
        "      batch_var = torch.var(x, dim=0)\n",
        "      \n",
        "      x = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
        "\n",
        "      self.running_mean = self.momentum * batch_mean.detach() + (1 - self.momentum) * self.running_mean\n",
        "      self.running_var = self.momentum * batch_var.detach() + (1 - self.momentum) * self.running_var\n",
        "    else:\n",
        "      x = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n",
        "\n",
        "    x = self.weight * x + self.bias\n",
        "    return x\n",
        "\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFN, self).__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*32*3, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size//2),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size//2),\n",
        "        nn.Linear(hidden_size//2, hidden_size//2),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size//2),\n",
        "        nn.Linear(hidden_size//2, 100)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUn7Fm36rCP-",
        "outputId": "71d13838-2fbb-414b-bde0-fbdea34672eb"
      },
      "source": [
        "torch.cuda.init()\n",
        "network = FFN()\n",
        "opt = SGD(network.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs = 40\n",
        "\n",
        "for epoch_ind in range(n_epochs):\n",
        "  train_loss, train_acc = [], []\n",
        "  \n",
        "  network.train()\n",
        "  for (X, Y) in train_dl:\n",
        "    opt.zero_grad()\n",
        "    Yp = network(X)\n",
        "    loss = loss_fn(Yp, Y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    accuracy = (Yp.argmax(1) == Y).float().mean()\n",
        "    train_acc.append(accuracy.detach())\n",
        "    train_loss.append(loss.detach())\n",
        "\n",
        "  print(f\"{epoch_ind} Train loss: {torch.stack(train_loss).mean():.6f}\\t acc: {torch.stack(train_acc).mean():.4f}\")\n",
        "\n",
        "  network.eval()\n",
        "  val_loss, val_acc = [], []\n",
        "\n",
        "  for (X, Y) in val_dl:\n",
        "    Yp = network(X)\n",
        "    \n",
        "    accuracy = (Yp.argmax(1) == Y).float().mean()\n",
        "    val_acc.append(accuracy)\n",
        "\n",
        "    loss = loss_fn(Yp, Y)\n",
        "    val_loss.append(loss)\n",
        "\n",
        "  print(f\"{epoch_ind} Val loss: {torch.stack(val_loss).mean():.6f}\\t acc: {torch.stack(val_acc).mean():.4f}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train loss: 4.679153\t acc: 0.0169\n",
            "0 Val loss: 4.600177\t acc: 0.0270\n",
            "1 Train loss: 4.515767\t acc: 0.0380\n",
            "1 Val loss: 4.470586\t acc: 0.0449\n",
            "2 Train loss: 4.413090\t acc: 0.0555\n",
            "2 Val loss: 4.370447\t acc: 0.0640\n",
            "3 Train loss: 4.327718\t acc: 0.0746\n",
            "3 Val loss: 4.285659\t acc: 0.0834\n",
            "4 Train loss: 4.252253\t acc: 0.0890\n",
            "4 Val loss: 4.217187\t acc: 0.0940\n",
            "5 Train loss: 4.190385\t acc: 0.1002\n",
            "5 Val loss: 4.153252\t acc: 0.1068\n",
            "6 Train loss: 4.133501\t acc: 0.1097\n",
            "6 Val loss: 4.092214\t acc: 0.1176\n",
            "7 Train loss: 4.084186\t acc: 0.1192\n",
            "7 Val loss: 4.056239\t acc: 0.1239\n",
            "8 Train loss: 4.042939\t acc: 0.1269\n",
            "8 Val loss: 4.005868\t acc: 0.1357\n",
            "9 Train loss: 4.000931\t acc: 0.1347\n",
            "9 Val loss: 3.978912\t acc: 0.1379\n",
            "10 Train loss: 3.962328\t acc: 0.1408\n",
            "10 Val loss: 3.922088\t acc: 0.1464\n",
            "11 Train loss: 3.929048\t acc: 0.1458\n",
            "11 Val loss: 3.900117\t acc: 0.1519\n",
            "12 Train loss: 3.898016\t acc: 0.1507\n",
            "12 Val loss: 3.867323\t acc: 0.1569\n",
            "13 Train loss: 3.866975\t acc: 0.1549\n",
            "13 Val loss: 3.839653\t acc: 0.1611\n",
            "14 Train loss: 3.837757\t acc: 0.1607\n",
            "14 Val loss: 3.819637\t acc: 0.1630\n",
            "15 Train loss: 3.809928\t acc: 0.1656\n",
            "15 Val loss: 3.791339\t acc: 0.1695\n",
            "16 Train loss: 3.784164\t acc: 0.1691\n",
            "16 Val loss: 3.764105\t acc: 0.1721\n",
            "17 Train loss: 3.757521\t acc: 0.1736\n",
            "17 Val loss: 3.738889\t acc: 0.1788\n",
            "18 Train loss: 3.735371\t acc: 0.1787\n",
            "18 Val loss: 3.712357\t acc: 0.1812\n",
            "19 Train loss: 3.710176\t acc: 0.1805\n",
            "19 Val loss: 3.684084\t acc: 0.1856\n",
            "20 Train loss: 3.688774\t acc: 0.1846\n",
            "20 Val loss: 3.659141\t acc: 0.1890\n",
            "21 Train loss: 3.667568\t acc: 0.1886\n",
            "21 Val loss: 3.644920\t acc: 0.1913\n",
            "22 Train loss: 3.644706\t acc: 0.1920\n",
            "22 Val loss: 3.628203\t acc: 0.1962\n",
            "23 Train loss: 3.623743\t acc: 0.1943\n",
            "23 Val loss: 3.618592\t acc: 0.1964\n",
            "24 Train loss: 3.605402\t acc: 0.1972\n",
            "24 Val loss: 3.593551\t acc: 0.2018\n",
            "25 Train loss: 3.586753\t acc: 0.2022\n",
            "25 Val loss: 3.579695\t acc: 0.2034\n",
            "26 Train loss: 3.566078\t acc: 0.2044\n",
            "26 Val loss: 3.552220\t acc: 0.2056\n",
            "27 Train loss: 3.546269\t acc: 0.2098\n",
            "27 Val loss: 3.534546\t acc: 0.2096\n",
            "28 Train loss: 3.528364\t acc: 0.2121\n",
            "28 Val loss: 3.511056\t acc: 0.2115\n",
            "29 Train loss: 3.510128\t acc: 0.2143\n",
            "29 Val loss: 3.489616\t acc: 0.2167\n",
            "30 Train loss: 3.490389\t acc: 0.2189\n",
            "30 Val loss: 3.469536\t acc: 0.2210\n",
            "31 Train loss: 3.475932\t acc: 0.2208\n",
            "31 Val loss: 3.454343\t acc: 0.2238\n",
            "32 Train loss: 3.458840\t acc: 0.2233\n",
            "32 Val loss: 3.449950\t acc: 0.2253\n",
            "33 Train loss: 3.442073\t acc: 0.2252\n",
            "33 Val loss: 3.459967\t acc: 0.2232\n",
            "34 Train loss: 3.426214\t acc: 0.2279\n",
            "34 Val loss: 3.414595\t acc: 0.2334\n",
            "35 Train loss: 3.407106\t acc: 0.2329\n",
            "35 Val loss: 3.393553\t acc: 0.2365\n",
            "36 Train loss: 3.389818\t acc: 0.2369\n",
            "36 Val loss: 3.375656\t acc: 0.2399\n",
            "37 Train loss: 3.374552\t acc: 0.2385\n",
            "37 Val loss: 3.358344\t acc: 0.2391\n",
            "38 Train loss: 3.359281\t acc: 0.2423\n",
            "38 Val loss: 3.340178\t acc: 0.2461\n",
            "39 Train loss: 3.343874\t acc: 0.2448\n",
            "39 Val loss: 3.337270\t acc: 0.2424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh5ZdarS42he"
      },
      "source": [
        "0 Train loss: 4.679153\t acc: 0.0169\n",
        "0 Val loss: 4.600177\t acc: 0.0270\n",
        "1 Train loss: 4.515767\t acc: 0.0380\n",
        "1 Val loss: 4.470586\t acc: 0.0449\n",
        "2 Train loss: 4.413090\t acc: 0.0555\n",
        "2 Val loss: 4.370447\t acc: 0.0640\n",
        "3 Train loss: 4.327718\t acc: 0.0746\n",
        "3 Val loss: 4.285659\t acc: 0.0834\n",
        "4 Train loss: 4.252253\t acc: 0.0890\n",
        "4 Val loss: 4.217187\t acc: 0.0940\n",
        "5 Train loss: 4.190385\t acc: 0.1002\n",
        "5 Val loss: 4.153252\t acc: 0.1068\n",
        "6 Train loss: 4.133501\t acc: 0.1097\n",
        "6 Val loss: 4.092214\t acc: 0.1176\n",
        "7 Train loss: 4.084186\t acc: 0.1192\n",
        "7 Val loss: 4.056239\t acc: 0.1239\n",
        "8 Train loss: 4.042939\t acc: 0.1269\n",
        "8 Val loss: 4.005868\t acc: 0.1357\n",
        "9 Train loss: 4.000931\t acc: 0.1347\n",
        "9 Val loss: 3.978912\t acc: 0.1379\n",
        "10 Train loss: 3.962328\t acc: 0.1408\n",
        "10 Val loss: 3.922088\t acc: 0.1464\n",
        "11 Train loss: 3.929048\t acc: 0.1458\n",
        "11 Val loss: 3.900117\t acc: 0.1519\n",
        "12 Train loss: 3.898016\t acc: 0.1507\n",
        "12 Val loss: 3.867323\t acc: 0.1569\n",
        "13 Train loss: 3.866975\t acc: 0.1549\n",
        "13 Val loss: 3.839653\t acc: 0.1611\n",
        "14 Train loss: 3.837757\t acc: 0.1607\n",
        "14 Val loss: 3.819637\t acc: 0.1630\n",
        "15 Train loss: 3.809928\t acc: 0.1656\n",
        "15 Val loss: 3.791339\t acc: 0.1695\n",
        "16 Train loss: 3.784164\t acc: 0.1691\n",
        "16 Val loss: 3.764105\t acc: 0.1721\n",
        "17 Train loss: 3.757521\t acc: 0.1736\n",
        "17 Val loss: 3.738889\t acc: 0.1788\n",
        "18 Train loss: 3.735371\t acc: 0.1787\n",
        "18 Val loss: 3.712357\t acc: 0.1812\n",
        "19 Train loss: 3.710176\t acc: 0.1805\n",
        "19 Val loss: 3.684084\t acc: 0.1856\n",
        "20 Train loss: 3.688774\t acc: 0.1846\n",
        "20 Val loss: 3.659141\t acc: 0.1890\n",
        "21 Train loss: 3.667568\t acc: 0.1886\n",
        "21 Val loss: 3.644920\t acc: 0.1913\n",
        "22 Train loss: 3.644706\t acc: 0.1920\n",
        "22 Val loss: 3.628203\t acc: 0.1962\n",
        "23 Train loss: 3.623743\t acc: 0.1943\n",
        "23 Val loss: 3.618592\t acc: 0.1964\n",
        "24 Train loss: 3.605402\t acc: 0.1972\n",
        "24 Val loss: 3.593551\t acc: 0.2018\n",
        "25 Train loss: 3.586753\t acc: 0.2022\n",
        "25 Val loss: 3.579695\t acc: 0.2034\n",
        "26 Train loss: 3.566078\t acc: 0.2044\n",
        "26 Val loss: 3.552220\t acc: 0.2056\n",
        "27 Train loss: 3.546269\t acc: 0.2098\n",
        "27 Val loss: 3.534546\t acc: 0.2096\n",
        "28 Train loss: 3.528364\t acc: 0.2121\n",
        "28 Val loss: 3.511056\t acc: 0.2115\n",
        "29 Train loss: 3.510128\t acc: 0.2143\n",
        "29 Val loss: 3.489616\t acc: 0.2167\n",
        "30 Train loss: 3.490389\t acc: 0.2189\n",
        "30 Val loss: 3.469536\t acc: 0.2210\n",
        "31 Train loss: 3.475932\t acc: 0.2208\n",
        "31 Val loss: 3.454343\t acc: 0.2238\n",
        "32 Train loss: 3.458840\t acc: 0.2233\n",
        "32 Val loss: 3.449950\t acc: 0.2253\n",
        "33 Train loss: 3.442073\t acc: 0.2252\n",
        "33 Val loss: 3.459967\t acc: 0.2232\n",
        "34 Train loss: 3.426214\t acc: 0.2279\n",
        "34 Val loss: 3.414595\t acc: 0.2334\n",
        "35 Train loss: 3.407106\t acc: 0.2329\n",
        "35 Val loss: 3.393553\t acc: 0.2365\n",
        "36 Train loss: 3.389818\t acc: 0.2369\n",
        "36 Val loss: 3.375656\t acc: 0.2399\n",
        "37 Train loss: 3.374552\t acc: 0.2385\n",
        "37 Val loss: 3.358344\t acc: 0.2391\n",
        "38 Train loss: 3.359281\t acc: 0.2423\n",
        "38 Val loss: 3.340178\t acc: 0.2461\n",
        "39 Train loss: 3.343874\t acc: 0.2448\n",
        "39 Val loss: 3.337270\t acc: 0.2424"
      ]
    }
  ]
}