{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hometask5_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpDsT3IW0cte+5sgMBSLvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpysmennyi/machinelearning-learning/blob/main/hometask5_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boRyS8A_vObR"
      },
      "source": [
        "CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poyJfczGpVr4",
        "outputId": "d0f4c2c8-7ded-4adf-b639-03844b430b44"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms \n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "train_ds = CIFAR10('.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "val_ds = CIFAR10('.', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "batch_size = 128\n",
        "hidden_size = 128\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class BatchNorm(nn.Module):\n",
        "  def __init__(self, n_features, momentum=0.1, eps=1e-5):\n",
        "    super(BatchNorm, self).__init__()\n",
        "    self.momentum = momentum\n",
        "    self.eps = eps\n",
        "    \n",
        "    # afine parameters\n",
        "    self.weight = nn.Parameter(torch.Tensor(n_features))\n",
        "    self.bias = nn.Parameter(torch.Tensor(n_features))\n",
        "\n",
        "    # running statistics\n",
        "    self.register_buffer('running_mean', torch.zeros(n_features))\n",
        "    self.register_buffer('running_var', torch.zeros(n_features))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.ones_(self.weight)\n",
        "    nn.init.zeros_(self.bias)\n",
        "    self.running_mean.zero_()\n",
        "    self.running_var.fill_(1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.training:\n",
        "      batch_mean = torch.mean(x, dim=0)\n",
        "      batch_var = torch.var(x, dim=0)\n",
        "      \n",
        "      x = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
        "\n",
        "      self.running_mean = self.momentum * batch_mean.detach() + (1 - self.momentum) * self.running_mean\n",
        "      self.running_var = self.momentum * batch_var.detach() + (1 - self.momentum) * self.running_var\n",
        "    else:\n",
        "      x = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n",
        "\n",
        "    x = self.weight * x + self.bias\n",
        "    return x\n",
        "\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFN, self).__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*32*3, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        BatchNorm(hidden_size),\n",
        "        nn.Linear(hidden_size, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UesMXOP5pjgI",
        "outputId": "b8e99509-dec5-40fe-9767-0cf19c4e3e2c"
      },
      "source": [
        "torch.cuda.init()\n",
        "network = FFN()\n",
        "opt = SGD(network.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs = 50\n",
        "\n",
        "for epoch_ind in range(n_epochs):\n",
        "  train_loss, train_acc = [], []\n",
        "  \n",
        "  network.train()\n",
        "  for (X, Y) in train_dl:\n",
        "    opt.zero_grad()\n",
        "    Yp = network(X)\n",
        "    loss = loss_fn(Yp, Y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    accuracy = (Yp.argmax(1) == Y).float().mean()\n",
        "    train_acc.append(accuracy.detach())\n",
        "    train_loss.append(loss.detach())\n",
        "\n",
        "  print(f\"{epoch_ind} Train loss: {torch.stack(train_loss).mean():.6f}\\t acc: {torch.stack(train_acc).mean():.4f}\")\n",
        "\n",
        "  network.eval()\n",
        "  val_loss, val_acc = [], []\n",
        "  for (X, Y) in val_dl:\n",
        "    Yp = network(X)\n",
        "    \n",
        "    accuracy = (Yp.argmax(1) == Y).float().mean()\n",
        "    val_acc.append(accuracy)\n",
        "\n",
        "    loss = loss_fn(Yp, Y)\n",
        "    val_loss.append(loss)\n",
        "\n",
        "  print(f\"{epoch_ind} Val loss: {torch.stack(val_loss).mean():.6f}\\t acc: {torch.stack(val_acc).mean():.4f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train loss: 1.990762\t acc: 0.2915\n",
            "0 Val loss: 1.846510\t acc: 0.3478\n",
            "1 Train loss: 1.779000\t acc: 0.3769\n",
            "1 Val loss: 1.731272\t acc: 0.3925\n",
            "2 Train loss: 1.695809\t acc: 0.4091\n",
            "2 Val loss: 1.656721\t acc: 0.4233\n",
            "3 Train loss: 1.643051\t acc: 0.4269\n",
            "3 Val loss: 1.622609\t acc: 0.4362\n",
            "4 Train loss: 1.602857\t acc: 0.4424\n",
            "4 Val loss: 1.578662\t acc: 0.4498\n",
            "5 Train loss: 1.572059\t acc: 0.4518\n",
            "5 Val loss: 1.547497\t acc: 0.4570\n",
            "6 Train loss: 1.539851\t acc: 0.4598\n",
            "6 Val loss: 1.514074\t acc: 0.4683\n",
            "7 Train loss: 1.514478\t acc: 0.4688\n",
            "7 Val loss: 1.498815\t acc: 0.4763\n",
            "8 Train loss: 1.490176\t acc: 0.4788\n",
            "8 Val loss: 1.501155\t acc: 0.4734\n",
            "9 Train loss: 1.471220\t acc: 0.4860\n",
            "9 Val loss: 1.472072\t acc: 0.4830\n",
            "10 Train loss: 1.450944\t acc: 0.4918\n",
            "10 Val loss: 1.430384\t acc: 0.4981\n",
            "11 Train loss: 1.432522\t acc: 0.4978\n",
            "11 Val loss: 1.419469\t acc: 0.5031\n",
            "12 Train loss: 1.419272\t acc: 0.5031\n",
            "12 Val loss: 1.412776\t acc: 0.5052\n",
            "13 Train loss: 1.402765\t acc: 0.5102\n",
            "13 Val loss: 1.389674\t acc: 0.5142\n",
            "14 Train loss: 1.389489\t acc: 0.5137\n",
            "14 Val loss: 1.385977\t acc: 0.5130\n",
            "15 Train loss: 1.372732\t acc: 0.5187\n",
            "15 Val loss: 1.421266\t acc: 0.5007\n",
            "16 Train loss: 1.359489\t acc: 0.5248\n",
            "16 Val loss: 1.363912\t acc: 0.5219\n",
            "17 Train loss: 1.345128\t acc: 0.5292\n",
            "17 Val loss: 1.341355\t acc: 0.5283\n",
            "18 Train loss: 1.332304\t acc: 0.5350\n",
            "18 Val loss: 1.362472\t acc: 0.5179\n",
            "19 Train loss: 1.319085\t acc: 0.5387\n",
            "19 Val loss: 1.313122\t acc: 0.5404\n",
            "20 Train loss: 1.309508\t acc: 0.5419\n",
            "20 Val loss: 1.300110\t acc: 0.5456\n",
            "21 Train loss: 1.298185\t acc: 0.5442\n",
            "21 Val loss: 1.306535\t acc: 0.5400\n",
            "22 Train loss: 1.285946\t acc: 0.5499\n",
            "22 Val loss: 1.274118\t acc: 0.5545\n",
            "23 Train loss: 1.274307\t acc: 0.5557\n",
            "23 Val loss: 1.274320\t acc: 0.5520\n",
            "24 Train loss: 1.264695\t acc: 0.5589\n",
            "24 Val loss: 1.307747\t acc: 0.5415\n",
            "25 Train loss: 1.252475\t acc: 0.5637\n",
            "25 Val loss: 1.304033\t acc: 0.5400\n",
            "26 Train loss: 1.243024\t acc: 0.5646\n",
            "26 Val loss: 1.268712\t acc: 0.5500\n",
            "27 Train loss: 1.232908\t acc: 0.5708\n",
            "27 Val loss: 1.254438\t acc: 0.5603\n",
            "28 Train loss: 1.221766\t acc: 0.5734\n",
            "28 Val loss: 1.234352\t acc: 0.5709\n",
            "29 Train loss: 1.215171\t acc: 0.5744\n",
            "29 Val loss: 1.214465\t acc: 0.5741\n",
            "30 Train loss: 1.204532\t acc: 0.5802\n",
            "30 Val loss: 1.283087\t acc: 0.5537\n",
            "31 Train loss: 1.195120\t acc: 0.5821\n",
            "31 Val loss: 1.279645\t acc: 0.5550\n",
            "32 Train loss: 1.187408\t acc: 0.5840\n",
            "32 Val loss: 1.216128\t acc: 0.5724\n",
            "33 Train loss: 1.178394\t acc: 0.5882\n",
            "33 Val loss: 1.176677\t acc: 0.5861\n",
            "34 Train loss: 1.168763\t acc: 0.5916\n",
            "34 Val loss: 1.197605\t acc: 0.5799\n",
            "35 Train loss: 1.158991\t acc: 0.5955\n",
            "35 Val loss: 1.319411\t acc: 0.5289\n",
            "36 Train loss: 1.152077\t acc: 0.5980\n",
            "36 Val loss: 1.213666\t acc: 0.5773\n",
            "37 Train loss: 1.144534\t acc: 0.5991\n",
            "37 Val loss: 1.219435\t acc: 0.5688\n",
            "38 Train loss: 1.135619\t acc: 0.6023\n",
            "38 Val loss: 1.135689\t acc: 0.6032\n",
            "39 Train loss: 1.129149\t acc: 0.6059\n",
            "39 Val loss: 1.174253\t acc: 0.5869\n",
            "40 Train loss: 1.120166\t acc: 0.6097\n",
            "40 Val loss: 1.110891\t acc: 0.6108\n",
            "41 Train loss: 1.110771\t acc: 0.6110\n",
            "41 Val loss: 1.258806\t acc: 0.5482\n",
            "42 Train loss: 1.101712\t acc: 0.6169\n",
            "42 Val loss: 1.197847\t acc: 0.5762\n",
            "43 Train loss: 1.095484\t acc: 0.6208\n",
            "43 Val loss: 1.256672\t acc: 0.5547\n",
            "44 Train loss: 1.088135\t acc: 0.6182\n",
            "44 Val loss: 1.099282\t acc: 0.6174\n",
            "45 Train loss: 1.078006\t acc: 0.6244\n",
            "45 Val loss: 1.133403\t acc: 0.6018\n",
            "46 Train loss: 1.071571\t acc: 0.6248\n",
            "46 Val loss: 1.134904\t acc: 0.6011\n",
            "47 Train loss: 1.065476\t acc: 0.6262\n",
            "47 Val loss: 1.161636\t acc: 0.5844\n",
            "48 Train loss: 1.058355\t acc: 0.6297\n",
            "48 Val loss: 1.100878\t acc: 0.6143\n",
            "49 Train loss: 1.050132\t acc: 0.6327\n",
            "49 Val loss: 1.147772\t acc: 0.5989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCQAeMxRvcZa"
      },
      "source": [
        "batch_size = 128,\n",
        "hidden_size = 128,\n",
        "ReLU,\n",
        "LR =0.001,\n",
        "epochs = 50,\n",
        "Batch Normalization\n",
        "\n",
        "0 Train loss: 1.990762\t acc: 0.2915\n",
        "0 Val loss: 1.846510\t acc: 0.3478\n",
        "1 Train loss: 1.779000\t acc: 0.3769\n",
        "1 Val loss: 1.731272\t acc: 0.3925\n",
        "2 Train loss: 1.695809\t acc: 0.4091\n",
        "2 Val loss: 1.656721\t acc: 0.4233\n",
        "3 Train loss: 1.643051\t acc: 0.4269\n",
        "3 Val loss: 1.622609\t acc: 0.4362\n",
        "4 Train loss: 1.602857\t acc: 0.4424\n",
        "4 Val loss: 1.578662\t acc: 0.4498\n",
        "5 Train loss: 1.572059\t acc: 0.4518\n",
        "5 Val loss: 1.547497\t acc: 0.4570\n",
        "6 Train loss: 1.539851\t acc: 0.4598\n",
        "6 Val loss: 1.514074\t acc: 0.4683\n",
        "7 Train loss: 1.514478\t acc: 0.4688\n",
        "7 Val loss: 1.498815\t acc: 0.4763\n",
        "8 Train loss: 1.490176\t acc: 0.4788\n",
        "8 Val loss: 1.501155\t acc: 0.4734\n",
        "9 Train loss: 1.471220\t acc: 0.4860\n",
        "9 Val loss: 1.472072\t acc: 0.4830\n",
        "10 Train loss: 1.450944\t acc: 0.4918\n",
        "10 Val loss: 1.430384\t acc: 0.4981\n",
        "11 Train loss: 1.432522\t acc: 0.4978\n",
        "11 Val loss: 1.419469\t acc: 0.5031\n",
        "12 Train loss: 1.419272\t acc: 0.5031\n",
        "12 Val loss: 1.412776\t acc: 0.5052\n",
        "13 Train loss: 1.402765\t acc: 0.5102\n",
        "13 Val loss: 1.389674\t acc: 0.5142\n",
        "14 Train loss: 1.389489\t acc: 0.5137\n",
        "14 Val loss: 1.385977\t acc: 0.5130\n",
        "15 Train loss: 1.372732\t acc: 0.5187\n",
        "15 Val loss: 1.421266\t acc: 0.5007\n",
        "16 Train loss: 1.359489\t acc: 0.5248\n",
        "16 Val loss: 1.363912\t acc: 0.5219\n",
        "17 Train loss: 1.345128\t acc: 0.5292\n",
        "17 Val loss: 1.341355\t acc: 0.5283\n",
        "18 Train loss: 1.332304\t acc: 0.5350\n",
        "18 Val loss: 1.362472\t acc: 0.5179\n",
        "19 Train loss: 1.319085\t acc: 0.5387\n",
        "19 Val loss: 1.313122\t acc: 0.5404\n",
        "20 Train loss: 1.309508\t acc: 0.5419\n",
        "20 Val loss: 1.300110\t acc: 0.5456\n",
        "21 Train loss: 1.298185\t acc: 0.5442\n",
        "21 Val loss: 1.306535\t acc: 0.5400\n",
        "22 Train loss: 1.285946\t acc: 0.5499\n",
        "22 Val loss: 1.274118\t acc: 0.5545\n",
        "23 Train loss: 1.274307\t acc: 0.5557\n",
        "23 Val loss: 1.274320\t acc: 0.5520\n",
        "24 Train loss: 1.264695\t acc: 0.5589\n",
        "24 Val loss: 1.307747\t acc: 0.5415\n",
        "25 Train loss: 1.252475\t acc: 0.5637\n",
        "25 Val loss: 1.304033\t acc: 0.5400\n",
        "26 Train loss: 1.243024\t acc: 0.5646\n",
        "26 Val loss: 1.268712\t acc: 0.5500\n",
        "27 Train loss: 1.232908\t acc: 0.5708\n",
        "27 Val loss: 1.254438\t acc: 0.5603\n",
        "28 Train loss: 1.221766\t acc: 0.5734\n",
        "28 Val loss: 1.234352\t acc: 0.5709\n",
        "29 Train loss: 1.215171\t acc: 0.5744\n",
        "29 Val loss: 1.214465\t acc: 0.5741\n",
        "30 Train loss: 1.204532\t acc: 0.5802\n",
        "30 Val loss: 1.283087\t acc: 0.5537\n",
        "31 Train loss: 1.195120\t acc: 0.5821\n",
        "31 Val loss: 1.279645\t acc: 0.5550\n",
        "32 Train loss: 1.187408\t acc: 0.5840\n",
        "32 Val loss: 1.216128\t acc: 0.5724\n",
        "33 Train loss: 1.178394\t acc: 0.5882\n",
        "33 Val loss: 1.176677\t acc: 0.5861\n",
        "34 Train loss: 1.168763\t acc: 0.5916\n",
        "34 Val loss: 1.197605\t acc: 0.5799\n",
        "35 Train loss: 1.158991\t acc: 0.5955\n",
        "35 Val loss: 1.319411\t acc: 0.5289\n",
        "36 Train loss: 1.152077\t acc: 0.5980\n",
        "36 Val loss: 1.213666\t acc: 0.5773\n",
        "37 Train loss: 1.144534\t acc: 0.5991\n",
        "37 Val loss: 1.219435\t acc: 0.5688\n",
        "38 Train loss: 1.135619\t acc: 0.6023\n",
        "38 Val loss: 1.135689\t acc: 0.6032\n",
        "39 Train loss: 1.129149\t acc: 0.6059\n",
        "39 Val loss: 1.174253\t acc: 0.5869\n",
        "40 Train loss: 1.120166\t acc: 0.6097\n",
        "40 Val loss: 1.110891\t acc: 0.6108\n",
        "41 Train loss: 1.110771\t acc: 0.6110\n",
        "41 Val loss: 1.258806\t acc: 0.5482\n",
        "42 Train loss: 1.101712\t acc: 0.6169\n",
        "42 Val loss: 1.197847\t acc: 0.5762\n",
        "43 Train loss: 1.095484\t acc: 0.6208\n",
        "43 Val loss: 1.256672\t acc: 0.5547\n",
        "44 Train loss: 1.088135\t acc: 0.6182\n",
        "44 Val loss: 1.099282\t acc: 0.6174\n",
        "45 Train loss: 1.078006\t acc: 0.6244\n",
        "45 Val loss: 1.133403\t acc: 0.6018\n",
        "46 Train loss: 1.071571\t acc: 0.6248\n",
        "46 Val loss: 1.134904\t acc: 0.6011\n",
        "47 Train loss: 1.065476\t acc: 0.6262\n",
        "47 Val loss: 1.161636\t acc: 0.5844\n",
        "48 Train loss: 1.058355\t acc: 0.6297\n",
        "48 Val loss: 1.100878\t acc: 0.6143\n",
        "49 Train loss: 1.050132\t acc: 0.6327\n",
        "49 Val loss: 1.147772\t acc: 0.5989"
      ]
    }
  ]
}